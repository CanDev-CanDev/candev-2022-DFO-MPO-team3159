{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Whales.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CanDev2022 Challenge: Whales and ships: shall they never meet\n",
        "### Team Name: The Killer Whales\n",
        "\n",
        "This code converts the provided AIS data from CSV files into a raster format that is much smaller (from 490 MB down to 3 MB) and more suitable for quick interactions in our R Shiny app.\n",
        "\n",
        "Location precision is relatively low in the produced raster files; this was chosen to match the other provided raster dataset on whale habitat suitability. Keeping both datasets on the same scale facilitates direct comparisons within the app.\n",
        "\n",
        "This code also begins work to bring data into a single table based on the AIS CSV's, to facilitate future experiments with machine learning algorithms for model generation and optimization.\n",
        "\n",
        "Code was run on Google Colaboratory, with the following folder structure in Google Drive:\n",
        "\n",
        "/CanDev22\n",
        "\n",
        ". ../data\n",
        "\n",
        ". ../ais .........Provided AIS data (CSV files)\n",
        "\n",
        ". ../dsz ........Designated Slow Zones (geojson)\n",
        "\n",
        ". ../tif ...........Whale habitat files (tif)\n",
        "\n",
        ". . ../new .....Converted AIS data (tif)"
      ],
      "metadata": {
        "id": "CMy8d1Yi0__A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axUukWvtnyke",
        "outputId": "30dd112b-88e2-41b7-c6df-ed97ccc7dbe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.7)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install rasterio\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry import Polygon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPBGMrB6n8Vo",
        "outputId": "81297330-7e8c-4f20-dca1-a7bcaab560ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a 'SpeedViolation' boolean attribute to each record"
      ],
      "metadata": {
        "id": "z1tXfIG80y1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all monthly files of the AIS data (csv files) into one dataframe.\n",
        "# Many columns are currently irrelevant, but are kept as attributes for\n",
        "# future work on model generation / optimization with machine learning.\n",
        "\n",
        "ais_dir = \"/content/gdrive/MyDrive/CanDev22/data/ais\"\n",
        "df_ais  = pd.DataFrame()\n",
        "\n",
        "for ais_file in os.listdir(ais_dir):\n",
        "  if ais_file.endswith(\".csv\"):\n",
        "    ais_filepath = os.path.join(ais_dir, ais_file)\n",
        "    #print(ais_filepath)\n",
        "    df_ais = df_ais.append(pd.read_csv(ais_filepath))\n",
        "\n",
        "print('Number of records: %d' % df_ais.shape[0])\n",
        "print('Number of columns: %d' % df_ais.shape[1])\n",
        "print('\\nColumn names: %s' % df_ais.columns)\n",
        "#df_ais.describe(include='all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnUBki9Wn_-S",
        "outputId": "0947dd59-d402-4699-d14c-f639c3eedc9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records: 5016275\n",
            "Number of columns: 15\n",
            "\n",
            "Column names: Index(['MMSI', 'UTC_Timestamp', 'Lat', 'Lon', 'SOG', 'COG', 'Heading',\n",
            "       'VesselName', 'VesselType', 'Status', 'Length', 'Width', 'Draft',\n",
            "       'Cargo', 'TransceiverClass'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Designated Slow Zones (geojson files)\n",
        "\n",
        "dsz_dir = \"/content/gdrive/MyDrive/CanDev22/data/dsz/\"\n",
        "\n",
        "with open(dsz_dir+'Block_Island_Sound_Nov_1-Apr_30.geojson', 'r') as json_file:\n",
        "       zone1_json = json.load(json_file)\n",
        "with open(dsz_dir+'Cape_Cod_Bay_Jan_1-May_15.geojson', 'r') as json_file:\n",
        "       zone2_json = json.load(json_file)\n",
        "with open(dsz_dir+'Great_South_Channel_Apr_1-Jul_31.geojson', 'r') as json_file:\n",
        "       zone3_json = json.load(json_file)\n",
        "with open(dsz_dir+'Off_Race_Point_Mar_1-Apr_30.geojson', 'r') as json_file:\n",
        "       zone4_json = json.load(json_file)\n",
        "\n",
        "# Set up zone 'seasons' when in effect\n",
        "# (Zone 1 has two date ranges in this single year of data, as it spans Dec/Jan)\n",
        "\n",
        "z1a_start = pd.Timestamp(2020,1,1)\n",
        "z1a_end   = pd.Timestamp(2020,4,30)\n",
        "z1b_start = pd.Timestamp(2020,11,1)\n",
        "z1b_end   = pd.Timestamp(2020,12,31)\n",
        "z2_start  = pd.Timestamp(2020,1,1)\n",
        "z2_end    = pd.Timestamp(2020,5,15)\n",
        "z3_start  = pd.Timestamp(2020,4,1)\n",
        "z3_end    = pd.Timestamp(2020,7,31)\n",
        "z4_start  = pd.Timestamp(2020,3,1)\n",
        "z4_end    = pd.Timestamp(2020,4,30)\n",
        "\n",
        "# Create zone boundary Polygons and confirm they're as expected with test points\n",
        "\n",
        "zone1_coords = zone1_json['features'][0]['geometry']['coordinates'][0]\n",
        "zone1_bounds = Polygon(zone1_coords)\n",
        "zone2_coords = zone2_json['features'][0]['geometry']['coordinates'][0]\n",
        "zone2_bounds = Polygon(zone2_coords)\n",
        "zone3_coords = zone3_json['features'][0]['geometry']['coordinates'][0]\n",
        "zone3_bounds = Polygon(zone3_coords)\n",
        "zone4_coords = zone4_json['features'][0]['geometry']['coordinates'][0]\n",
        "zone4_bounds = Polygon(zone4_coords)\n",
        "\n",
        "#one point inside each zone\n",
        "point1 = Point(-71.343, 40.959)\n",
        "point2 = Point(-70.3832,41.9971)\n",
        "point3 = Point(-68.4865,42.0559)\n",
        "point4 = Point(-70.0045,42.1995)\n",
        "\n",
        "#check zones each with one true and one false example \n",
        "print('Zone1: ', zone1_bounds.contains(point1), zone1_bounds.contains(point2))\n",
        "print('Zone2: ', zone2_bounds.contains(point2), zone2_bounds.contains(point3))\n",
        "print('Zone3: ', zone3_bounds.contains(point3), zone3_bounds.contains(point4))\n",
        "print('Zone4: ', zone4_bounds.contains(point4), zone4_bounds.contains(point1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpsPsI2opVnz",
        "outputId": "0ec63e45-f4f5-47c4-c8c9-bf4a2a0974ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zone1:  True False\n",
            "Zone2:  True False\n",
            "Zone3:  True False\n",
            "Zone4:  True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 'time' (pd.Timestamp datatype) from \"UTC_Timestamp\" for easy comparisons\n",
        "df_ais['time'] = df_ais.apply(lambda row: pd.Timestamp(row.UTC_Timestamp), axis=1)"
      ],
      "metadata": {
        "id": "w8Fmb9hasBbL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 'SpeedViolation' (boolean) from ship location, date, and speed.\n",
        "\n",
        "def speeding(rows):\n",
        "  return ((rows.SOG > 10) and (rows.Length >= 19.8) and (\n",
        "                #check if in zone1 during dates\n",
        "                (((rows.time >= z1a_start and \n",
        "                   rows.time <= z1a_end) or\n",
        "                  (rows.time >= z1b_start and\n",
        "                   rows.time <= z1b_end)) and\n",
        "                 (zone1_bounds.contains(Point(rows.Lon, rows.Lat)))) or\n",
        "                 #check if in zone2 during dates\n",
        "                 ((rows.time >= z2_start and \n",
        "                   rows.time <= z2_end) and\n",
        "                 (zone2_bounds.contains(Point(rows.Lon, rows.Lat)))) or\n",
        "                 #check if in zone3 during dates\n",
        "                 ((rows.time >= z3_start and \n",
        "                   rows.time <= z3_end) and\n",
        "                 #check if in zone4 during dates\n",
        "                 (zone3_bounds.contains(Point(rows.Lon, rows.Lat)))) or\n",
        "                 ((rows.time >= z4_start and \n",
        "                   rows.time <= z4_end) and\n",
        "                 (zone4_bounds.contains(Point(rows.Lon, rows.Lat)))) )\n",
        "  )\n",
        "\n",
        "df_ais['SpeedViolation'] = df_ais.apply(speeding, axis = 'columns')"
      ],
      "metadata": {
        "id": "fef-Zm-Wsojq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check new structure of dataframe\n",
        "print('Number of records: %d' % df_ais.shape[0])\n",
        "print('Number of columns: %d' % df_ais.shape[1])\n",
        "print('\\nColumn names: %s\\n' % df_ais.columns)\n",
        "#df_ais.describe(include='all')\n",
        "df_ais.SpeedViolation.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbDnuYZftTWG",
        "outputId": "72535fe1-1c81-41d6-a20a-553a0204c886"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records: 5016275\n",
            "Number of columns: 17\n",
            "\n",
            "Column names: Index(['MMSI', 'UTC_Timestamp', 'Lat', 'Lon', 'SOG', 'COG', 'Heading',\n",
            "       'VesselName', 'VesselType', 'Status', 'Length', 'Width', 'Draft',\n",
            "       'Cargo', 'TransceiverClass', 'time', 'SpeedViolation'],\n",
            "      dtype='object')\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    5013644\n",
              "True        2631\n",
              "Name: SpeedViolation, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate raster AIS data, for streamlined use with R Shiny app.\n"
      ],
      "metadata": {
        "id": "kVsZVyhwy1hO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load some habitat suitability raster data;\n",
        "#  just to copy the formatting, the R Shiny app will use the habitat raster data\n",
        "\n",
        "tif_dir = \"/content/gdrive/MyDrive/CanDev22/data/tif/\"\n",
        "\n",
        "raster_data = rasterio.open(tif_dir+'NARW_Apr_Norm.tif')\n",
        "raster = raster_data.read(1)\n",
        "\n",
        "# Check some meta-data, and a test point value \n",
        "raster_inds = raster_data.index(-69.4668,41.2763)\n",
        "raster_val = raster[raster_inds[0], raster_inds[1]]\n",
        "print('Old raster CRS: %s' % raster_data.crs)\n",
        "print('Old raster bounds: %s' % str(raster_data.bounds))\n",
        "print('Old raster grid data type: %s' % type(raster))\n",
        "print('Old raster grid dimensions: %s' % str(raster.shape))\n",
        "print('Old raster grid indices: %s' % str(raster_inds))\n",
        "print('Old raster grid cell value: %.3f' % raster_val)\n",
        "\n",
        "# Test a method for generating a new raster data file\n",
        "new_data = rasterio.open(tif_dir+'new.tif', mode='w+', driver=raster_data.driver,\n",
        "                    width=256, height=262, count=1, dtype=raster.dtype,\n",
        "                    crs=raster_data.crs, transform=raster_data.transform)\n",
        "new = new_data.read(1)\n",
        "\n",
        "# Confirm the meta-data, and a test point value are as expected\n",
        "new_inds = new_data.index(-69.4668,41.2763)\n",
        "new_val = new[new_inds[0], new_inds[1]]\n",
        "print('New raster CRS: %s' % new_data.crs)\n",
        "print('New raster bounds: %s' % str(new_data.bounds))\n",
        "print('New raster grid data type: %s' % type(new))\n",
        "print('New raster grid dimensions: %s' % str(new.shape))\n",
        "print('New raster grid indices: %s' % str(new_inds))\n",
        "print('New raster grid cell value: %.3f' % new_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTRuj2wvtZ3W",
        "outputId": "1f5c3ed6-e290-4bc4-ed2b-d177fb3b2cfb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old raster CRS: EPSG:4326\n",
            "Old raster bounds: BoundingBox(left=-82.6965062291361, bottom=22.9352776326434, right=-53.427044387514854, top=52.89074248617764)\n",
            "Old raster grid data type: <class 'numpy.ndarray'>\n",
            "Old raster grid dimensions: (262, 256)\n",
            "Old raster grid indices: (101, 115)\n",
            "Old raster grid cell value: 0.191\n",
            "New raster CRS: EPSG:4326\n",
            "New raster bounds: BoundingBox(left=-82.6965062291361, bottom=22.9352776326434, right=-53.427044387514854, top=52.89074248617764)\n",
            "New raster grid data type: <class 'numpy.ndarray'>\n",
            "New raster grid dimensions: (262, 256)\n",
            "New raster grid indices: (101, 115)\n",
            "New raster grid cell value: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Raster AIS data will factor in this lethality model based on ship speed.\n",
        "\n",
        "data_points = {0: 0,\n",
        "               3: 0.025813692,\n",
        "               5: 0.053872054,\n",
        "               7: 0.119191919,\n",
        "               9: 0.236139169,\n",
        "               11: 0.412794613,\n",
        "               13: 0.621997755,\n",
        "               15: 0.797306397,\n",
        "               17: 0.908417508,\n",
        "               19: 0.964534231,\n",
        "               21: 0.992592593,\n",
        "               23: 0.999775533}\n",
        "\n",
        "def leth_fnc(speed):\n",
        "  if (speed < 0): return 0\n",
        "  elif (speed > 23): return 0.999775533\n",
        "  else:\n",
        "    return np.interp(speed, list(data_points.keys()), list(data_points.values()))\n",
        "\n",
        "# Create the AIS raster data\n",
        "# Every transmission record increments the corresponding raster pixel by\n",
        "# the calculated lethality estimate of a ship/whale encounter.\n",
        "\n",
        "for ais_file in os.listdir(ais_dir):\n",
        "  if ais_file.endswith(\".csv\"):\n",
        "    ais_filepath = os.path.join(ais_dir, ais_file)\n",
        "    print(ais_filepath)\n",
        "    df = pd.read_csv(ais_filepath)\n",
        "    month_data = rasterio.open(tif_dir+'new/'+ais_file+'.tif', mode='w+',\n",
        "                               driver=raster_data.driver, width=256, height=262,\n",
        "                               count=1, dtype=raster.dtype, crs=raster_data.crs,\n",
        "                               transform=raster_data.transform)\n",
        "    month_read = month_data.read(1)\n",
        "    df = df.reset_index()\n",
        "    for index, row in df.iterrows():\n",
        "      month_inds = month_data.index(row['Lon'],row['Lat'])\n",
        "      month_read[month_inds[0], month_inds[1]] += (leth_fnc(row['SOG']))\n",
        "    month_data.write(month_read,1)  \n",
        "    month_data.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnidG3C6wcQt",
        "outputId": "64de6c0f-537b-4263-fe63-5672a47d5086"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_01_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_02_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_03_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_04_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_05_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_06_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_07_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_08_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_09_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_10_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_11_clean.csv\n",
            "/content/gdrive/MyDrive/CanDev22/data/ais/AIS_2020_12_clean.csv\n"
          ]
        }
      ]
    }
  ]
}